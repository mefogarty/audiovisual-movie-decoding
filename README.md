# audiovisual-movie-decoding

This repository contains code from the paper"Multisensory naturalistic decoding with high-density diffuse optical tomography". In particular, this repository contains the code for the decoding of audiovisual animated movies using a dataset of three adults watching at minimum 175 minutes of movie clips. This code uses a template-matching approach and allows users to adjust the number of clip options and the duration of the clips to challenge the decoder. More information on this method can be found in the citaiton below. 

## Data
Corresponding data for this manuscript is available here: https://www.nitrc.org/projects/neurodot/

Data for this repository is from the following two papers: https://doi.org/10.1117/1.NPh.12.1.015002 and https://doi.org/10.1002/hbm.26684

## Dependencies
This repository requires the following software: 
1. NeuroDOT v1.4 (https://www.nitrc.org/projects/neurodot/)
2. Matlab (including the Statistics and Machine Learning Toolbox)

## Citation
Kalyan Tripathy, Zachary E. Markow, Morgan Fogarty, Mariel L. Schroeder, Alexa M. Svoboda, Adam T. Eggebrecht, Bradley L. Schlaggar, Jason W. Trobaugh, Joseph P. Culver, "Multisensory naturalistic decoding with high-density diffuse optical tomography," Neurophoton. 12(1) 015002 (23 January 2025) https://doi.org/10.1117/1.NPh.12.1.015002
